{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deidentification of all Datasets\n",
    "\n",
    "#### - This script cleans the input datasets and deidentifies them with a randomly generated ID.\n",
    "#### - Note, each time you run this it will generate a new randomized ID list to de-identify the data.\n",
    "#### - Dates will not be adjsuted to \"DAYS\" - This happens downstream because dates are used as links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "\n",
    "import numpy as np\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (1,11,12,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Applications/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (1,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Applications/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load original Microbiology data\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Jan 2010 to Dec 2010) 2017-09-19-16-09-00.txt.ttx',\n",
    "                  sep = \"\\t\",\n",
    "                  quotechar='\"',\n",
    "                  skiprows=[0],\n",
    "                  header = None,\n",
    "                  low_memory=False)\n",
    "\n",
    "df2 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Jan 2011 to Mar 2012) 2017-09-19-16-09-10.txt.ttx',\n",
    "                  sep = \"\\t\",\n",
    "                  quotechar='\"',\n",
    "                  skiprows=[0],\n",
    "                  header = None,\n",
    "                  low_memory=False)\n",
    "\n",
    "df3 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Apr 2012 to Mar 2013) 2017-04-04-10-17-15.txt.ttx',\n",
    "                 sep = \"\\t\",\n",
    "                 quotechar='\"',\n",
    "                 skiprows=[0],\n",
    "                 header = None,\n",
    "                 low_memory=False)\n",
    "\n",
    "df4 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Apr 2013 to Mar 2014) 2017-04-04-13-56-59.txt.ttx',\n",
    "                 sep = \"\\t\",\n",
    "                 quotechar='\"',\n",
    "                 skiprows=[0],\n",
    "                 header = None,\n",
    "                 low_memory=False)\n",
    "\n",
    "df5 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Apr 2014 to Mar 2015) 2017-04-04-15-03-02.txt.ttx',\n",
    "                 sep = \"\\t\",\n",
    "                 quotechar='\"',\n",
    "                 skiprows=[0],\n",
    "                 header = None,\n",
    "                 low_memory=False)\n",
    "\n",
    "df6 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Apr 2015 to Mar 2016) 2017-04-04-19-36-01.txt.ttx',\n",
    "                 sep = \"\\t\",\n",
    "                 quotechar='\"',\n",
    "                 skiprows=[0],\n",
    "                 header = None,\n",
    "                 low_memory=False)\n",
    "\n",
    "df7 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Micro Bacterium Report_Harm (Apr 2016 to YTD) 2017-04-04-19-38-06.txt.ttx',\n",
    "                 sep = \"\\t\",\n",
    "                 quotechar='\"',\n",
    "                 skiprows=[0],\n",
    "                 header = None,\n",
    "                 low_memory=False)\n",
    "\n",
    "# Combine the separate files together\n",
    "dataframes = [df1, df2, df3, df4, df5, df6, df7]\n",
    "microlab = pd.concat(dataframes)\n",
    "\n",
    "# Relabel the columns\n",
    "microlab.columns = [\n",
    "    \"MRN\",\n",
    "    \"Unit_at_Order\",\n",
    "    \"Unit\",\n",
    "    \"Room\",\n",
    "    \"Bed\",\n",
    "    \"ORDERING_DATE\",\n",
    "    \"SPECIMEN_TAKEN_DATE\",\n",
    "    \"ACC_NUM\",\n",
    "    \"Source1\",\n",
    "    \"Source2\",\n",
    "    \"Line\",\n",
    "    \"Organism\",\n",
    "    \"Abx Name\",\n",
    "    \"ADMIT_DATE\",\n",
    "    \"Suscept\",\n",
    "    \"SENSITIVITY_VALUE\",\n",
    "    \"Order ID\",\n",
    "    \"Proc Code\",\n",
    "    \"Procedure\",\n",
    "    \"Result\"\n",
    "    ]\n",
    "\n",
    "# Fix the date format\n",
    "microlab['ORDERING_DATE'] = pd.to_datetime(microlab['ORDERING_DATE'], format = \"%m/%d/%y\")\n",
    "microlab['SPECIMEN_TAKEN_DATE'] = microlab['SPECIMEN_TAKEN_DATE'].str.split(' ').str[0]\n",
    "microlab['SPECIMEN_TAKEN_DATE'] = pd.to_datetime(microlab['SPECIMEN_TAKEN_DATE'], format = \"%m/%d/%Y\")\n",
    "microlab['ADMIT_DATE'] = microlab['ADMIT_DATE'].str.split(' ').str[0]\n",
    "microlab['ADMIT_DATE'] = pd.to_datetime(microlab['ADMIT_DATE'], format = \"%m/%d/%Y\")\n",
    "\n",
    "# Drop rows with missing information\n",
    "microlab = microlab.dropna(subset=['MRN', 'SPECIMEN_TAKEN_DATE', 'ACC_NUM', 'Organism', 'Abx Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load Encounters data\n",
    "\n",
    "df1 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Patients - Encounters (Kieran I Chacko) 2017-10-03-14-23-25.csv',\n",
    "                  sep = \",\",\n",
    "                  quotechar='\"',\n",
    "                  skiprows=[0],\n",
    "                  header = None,\n",
    "                  low_memory=False)\n",
    "\n",
    "encounters = df1\n",
    "\n",
    "# Relabel the columns\n",
    "encounters.columns = [\n",
    "    \"PAT_ENC_CSN_ID\",\n",
    "    \"ENCOUNTER_DATE\",\n",
    "    \"VISIT_ID\",\n",
    "    \"DEPARTMENT_NAME\",\n",
    "    \"ENCOUNTER_TYPE\",\n",
    "    \"MRN\",\n",
    "    \"AGE\",\n",
    "    \"SEX\",\n",
    "    \"BMI\",\n",
    "    \"SOCIAL_HX_TOBACCO_USER\",\n",
    "    \"HOSP_ADMSN_TIME\",\n",
    "    \"HOSP_DISCHRG_TIME\",\n",
    "    \"PREVIOUS_ADMISSION_DATE\",\n",
    "    \"PREVIOUS_DISCHARGE_DATE\",\n",
    "    \"TPN_IN_CURRENT_VISIT\",\n",
    "    \"COLORECTAL_CANCER_IN_CURRENT_VISIT\",\n",
    "    \"UC_IN_CURRENT_VISIT\",\n",
    "    \"CROHNS_IN_CURRENT_VISIT\",\n",
    "    \"IBD_IN_CURRENT_VISIT\",\n",
    "    \"IBS_IN_CURRENT_VISIT\"\n",
    "    ]\n",
    "\n",
    "# Fix the date format\n",
    "encounters.ix[encounters['HOSP_ADMSN_TIME'].isnull(), 'HOSP_ADMSN_TIME'] = encounters['ENCOUNTER_DATE']   # There are many non-admits that have NAN in this field. Let's assume that they are same day visits.\n",
    "encounters.ix[encounters['HOSP_DISCHRG_TIME'].isnull(), 'HOSP_DISCHRG_TIME'] = encounters['ENCOUNTER_DATE']   # There are many non-admits that have NAN in this field. Let's assume that they are same day visits.\n",
    "encounters['ENCOUNTER_DATE'] = pd.to_datetime(encounters['ENCOUNTER_DATE'], format = \"%m/%d/%Y\")\n",
    "encounters['HOSP_ADMSN_TIME'] = encounters['HOSP_ADMSN_TIME'].str.split(' ').str[0]\n",
    "encounters['HOSP_ADMSN_TIME'] = pd.to_datetime(encounters['HOSP_ADMSN_TIME'], format = \"%m/%d/%Y\")\n",
    "encounters['HOSP_DISCHRG_TIME'] = encounters['HOSP_DISCHRG_TIME'].str.split(' ').str[0]\n",
    "encounters['HOSP_DISCHRG_TIME'] = pd.to_datetime(encounters['HOSP_DISCHRG_TIME'], format = \"%m/%d/%Y\")\n",
    "\n",
    "encounters = encounters.sort_values(by = ['HOSP_ADMSN_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Medications data\n",
    "\n",
    "df1 = pd.read_csv('/Users/chackk02/Documents/Epic_Reports/Patients - Meds (Kieran I Chacko) 2017-10-03-14-12-35.csv',\n",
    "                  sep = \",\",\n",
    "                  quotechar='\"',\n",
    "                  skiprows=[0],\n",
    "                  header = None,\n",
    "                  low_memory = False)\n",
    "\n",
    "df2 = pd.read_csv('../Data/ABX_Keys.txt',\n",
    "                  sep = \"\\t\",\n",
    "                  quotechar='\"',\n",
    "                  skiprows=[0],\n",
    "                  header = None,\n",
    "                  low_memory = False)\n",
    "\n",
    "df3 = pd.read_csv('../Data/FREQ_Keys.txt',\n",
    "                  sep = \"\\t\",\n",
    "                  quotechar='\"',\n",
    "                  skiprows=[0],\n",
    "                  header = None,\n",
    "                  low_memory = False)\n",
    "\n",
    "medications = df1\n",
    "ABX = df2\n",
    "FREQ = df3\n",
    "\n",
    "medications.columns = [\"PAT_ENC_CSN_ID\",\n",
    "               \"ENCOUNTER_DATE\",\n",
    "               \"VISIT_ID\",\n",
    "               \"DEPARTMENT_NAME\",\n",
    "               \"ENCOUNTER_TYPE\",\n",
    "               \"MRN\",\n",
    "               \"ORDER_MED_ID\",\n",
    "               \"MEDICATION_ID\",\n",
    "               \"MED_NAME\",\n",
    "               \"ORDER_START_TIME\",\n",
    "               \"ORDER_END_TIME\",\n",
    "               \"DOSE\",\n",
    "               \"DOSE_UNIT\",\n",
    "               \"ROUTE\",\n",
    "               \"FREQ\",\n",
    "               \"TAKEN_TIME\"\n",
    "                       ]\n",
    "\n",
    "ABX.columns = ['Antibiotic-Treatment',\n",
    "              'ANTIBIOTIC_ID',\n",
    "              'MEDICATION_ID',\n",
    "              'MED_NAME',\n",
    "              'ATC_CODE',\n",
    "               'WHO_DOSE',\n",
    "               'WHO_DOSE_UNIT',\n",
    "               'WHO_ROUTE'\n",
    "              ]\n",
    "\n",
    "FREQ.columns = ['FREQ',\n",
    "              'FREQ_ADJ'\n",
    "               ]\n",
    "\n",
    "# Merge the Datasets togeter\n",
    "medications = pd.merge(medications, ABX, on='MEDICATION_ID', how='left')\n",
    "medications = pd.merge(medications, FREQ, on='FREQ', how='left')\n",
    "\n",
    "# Fix the date format\n",
    "medications['ENCOUNTER_DATE'] = pd.to_datetime(medications['ENCOUNTER_DATE'], format = \"%m/%d/%Y\")\n",
    "medications['ORDER_START_TIME'] = medications['ORDER_START_TIME'].str.split(' ').str[0]\n",
    "medications['ORDER_START_TIME'] = pd.to_datetime(medications['ORDER_START_TIME'], format = \"%m/%d/%Y\", errors = 'coerce')\n",
    "medications['ORDER_END_TIME'] = medications['ORDER_END_TIME'].str.split(' ').str[0]\n",
    "medications['ORDER_END_TIME'] = pd.to_datetime(medications['ORDER_END_TIME'], format = \"%m/%d/%Y\", errors = 'coerce')\n",
    "\n",
    "# Drop rows with missing information\n",
    "medications = medications.dropna(subset=['MRN', 'VISIT_ID', 'ENCOUNTER_DATE', 'Antibiotic-Treatment', 'ORDER_START_TIME', 'ORDER_END_TIME'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deidentify the data\n",
    "\n",
    "# Generate a Unique ID for the MRNs\n",
    "MRN = microlab['MRN'].unique()\n",
    "MRN = pd.DataFrame(MRN)\n",
    "MRN = MRN.sample(frac=1).reset_index(drop=True) # Randomly shuffles all of the rows\n",
    "MRN.columns = ['MRN']\n",
    "MRN['ID'] = MRN.index + 1\n",
    "\n",
    "# Save this file for future use\n",
    "MRN.to_csv('MRN_Key.txt', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Deidentify Microlab Data\n",
    "microlab = pd.merge(microlab, MRN, on=['MRN'], how = 'left')\n",
    "microlab = microlab.drop('MRN', 1)\n",
    "microlab.to_csv('Micro_Bacterium_Report-Deidentified.txt', sep='\\t', index=False)\n",
    "\n",
    "# Deidentify Encounters Data\n",
    "encounters = pd.merge(encounters, MRN, on='MRN', how='left')\n",
    "encounters = encounters.drop('MRN', 1)\n",
    "encounters.to_csv('Encounters_Report-Deidentified.txt', sep='\\t', index=False)\n",
    "\n",
    "# Deidentify Medications Data\n",
    "medications = pd.merge(medications, MRN, on='MRN', how='left')\n",
    "medications = medications.drop('MRN', 1)\n",
    "medications.to_csv('Medications_Report-Deidentified.txt', sep='\\t', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
